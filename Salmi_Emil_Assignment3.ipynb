{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract correct dataset\n",
    "from zipfile import ZipFile\n",
    "\n",
    "abst = ZipFile('abstracts.zip')\n",
    "\n",
    "for file in abst.namelist():\n",
    "    if file.startswith('abstracts/awards_2002/'):\n",
    "        abst.extract(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracts abstracts from documents\n",
    "import os\n",
    "\n",
    "rootdir = 'abstracts/awards_2002'\n",
    "documents = []\n",
    "\n",
    "for sdir, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        with open(os.path.join(sdir,file), \"rt\", encoding=\"unicode_escape\") as f:\n",
    "            documents.append([line.strip() for line in f.readlines()])\n",
    "            \n",
    "abstracts = []\n",
    "for d in documents:\n",
    "    s = \"\"\n",
    "    for i, t in enumerate(d):\n",
    "        if \"Abstract\" in t:\n",
    "            for t in d[i+1:]:\n",
    "                s += f\" {t}\"\n",
    "                \n",
    "    abstracts.append(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9923, 27299)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Set parameters and initialize\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=2, use_idf=True, sublinear_tf=True, max_df=0.8, max_features=50000)\n",
    "\n",
    "# Calcualate term-document matrix with tf-idf scores\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(abstracts)\n",
    "\n",
    "# Check matrix shape\n",
    "tfidf_matrix.toarray().shape # N_docs x N_terms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '0000', '0001', '000l', '001', '002', '003', '0085834', '01']\n",
      "['zorin', 'zr', 'zro2', 'zuni', 'zurich', 'zworski', 'zygmund', 'zygomycetes', 'zygomycota', 'zygotic']\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vectorizer.get_feature_names()[:10])\n",
    "print(tfidf_vectorizer.get_feature_names()[-10:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix[:,tfidf_vectorizer.get_feature_names().index('record')].toarray() # Get doc vector for term\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7632\tbe\n",
      "7419\ton\n",
      "7271\twith\n",
      "7167\tthat\n",
      "6656\tare\n",
      "6642\tresearch\n",
      "6561\tby\n",
      "6424\tas\n",
      "5968\tfrom\n",
      "5750\tan\n",
      "5402\tthese\n",
      "5401\tproject\n",
      "5365\tat\n",
      "4294\thave\n",
      "4108\twhich\n",
      "3958\tnew\n",
      "3739\tor\n",
      "3727\tit\n",
      "3669\ttheir\n",
      "3617\thas\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "terms_in_docs = tfidf_vectorizer.inverse_transform(tfidf_matrix)\n",
    "token_counter = Counter()\n",
    "for terms in terms_in_docs:\n",
    "    token_counter.update(terms)\n",
    "\n",
    "for term, count in token_counter.most_common(20):\n",
    "    print(\"%d\\t%s\" % (count, term))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 0, top terms by TF-IDF\n",
      "0.29\tchow\n",
      "0.19\thodge\n",
      "0.19\talgebraic\n",
      "0.14\tgeometry\n",
      "0.14\tsubgroup\n",
      "\n",
      "Document 1, top terms by TF-IDF\n",
      "0.24\tfriendships\n",
      "0.22\tcultivating\n",
      "0.21\tethnically\n",
      "0.20\tcontrol\n",
      "0.20\texchanging\n",
      "\n",
      "Document 2, top terms by TF-IDF\n",
      "0.24\tupdating\n",
      "0.17\treference\n",
      "0.17\tsecondly\n",
      "0.15\tdamped\n",
      "0.14\tvibrating\n",
      "\n",
      "Document 3, top terms by TF-IDF\n",
      "0.24\tconference\n",
      "0.20\tcomputations\n",
      "0.20\tlearn\n",
      "0.18\ttheory\n",
      "0.18\tgroup\n",
      "\n",
      "Document 4, top terms by TF-IDF\n",
      "0.21\tuncontrollable\n",
      "0.20\tcommonality\n",
      "0.19\tuncertainties\n",
      "0.18\tpreferences\n",
      "0.18\talternative\n"
     ]
    }
   ],
   "source": [
    "features = tfidf_vectorizer.get_feature_names()\n",
    "for doc_i in range(5):\n",
    "    print(\"\\nDocument %d, top terms by TF-IDF\" % doc_i)\n",
    "    for term, score in sorted(list(zip(features,tfidf_matrix.toarray()[doc_i])), key=lambda x:-x[1])[:5]:\n",
    "        print(\"%.2f\\t%s\" % (score, term))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_matrix.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document vector length: 27299\n",
      "Non-zero dimensions for document 0: 202\n",
      "Non-zero dimensions for document 1: 67\n",
      "Non-zero dimensions for document 2: 131\n",
      "Non-zero dimensions for document 3: 97\n",
      "Non-zero dimensions for document 4: 142\n"
     ]
    }
   ],
   "source": [
    "print(\"Document vector length:\", tfidf_matrix.shape[1])\n",
    "for i in range(5):\n",
    "    print(\"Non-zero dimensions for document %d: %d\" % (i, len([x for x in tfidf_matrix.toarray()[i] if x > 0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample word: activate\n",
      "Occurs in 110 documents\n",
      "out of 9923 documents\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample word:\", features[1000])\n",
    "print(\"Occurs in %d documents\" % len([x for x in tfidf_matrix.toarray()[:][1000] if x > 0]))\n",
    "print(\"out of %d documents\" % len(tfidf_matrix.toarray()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=30, random_state=123)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_sample = tfidf_matrix[:1000]\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Do clustering\n",
    "km = KMeans(n_clusters=30, random_state=123, verbose=0)\n",
    "km.fit(matrix_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq, numpy as np\n",
    "\n",
    "# Custom function to print top keywords for each cluster\n",
    "def print_clusters(matrix, clusters, n_keywords=10):\n",
    "    for cluster in range(min(clusters), max(clusters)+1):\n",
    "        cluster_docs = [i for i, c in enumerate(clusters) if c == cluster]\n",
    "        print(\"Cluster: %d (%d docs)\" % (cluster, len(cluster_docs)))\n",
    "        \n",
    "        # Keep scores for top n terms\n",
    "        new_matrix = np.zeros((len(cluster_docs), matrix.shape[1]))\n",
    "        for cluster_i, doc_vec in enumerate(matrix[cluster_docs].toarray()):\n",
    "            for idx, score in heapq.nlargest(n_keywords, enumerate(doc_vec), key=lambda x:x[1]):\n",
    "                new_matrix[cluster_i][idx] = score\n",
    "\n",
    "        # Aggregate scores for kept top terms\n",
    "        keywords = heapq.nlargest(n_keywords, zip(new_matrix.sum(axis=0), features))\n",
    "        print(', '.join([w for s,w in keywords]))\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22,  9,  1,  9, 28, 22, 15,  6, 27,  1, 12, 15,  8,  6,  9, 10,  7,\n",
       "        5,  1, 27, 20,  8, 20, 20, 12, 20, 10, 22,  1, 14, 12, 20,  6, 12,\n",
       "       12, 14,  6,  7,  6,  6, 26, 26, 20, 10, 20, 12, 22, 12,  1, 22,  6,\n",
       "       20,  7, 11, 29, 14, 12,  6, 10, 26, 22, 28, 11, 14, 26,  7, 12, 20,\n",
       "       22, 12,  8, 14,  8, 11,  7,  8, 28,  8,  5,  8, 11, 12, 11, 14,  7,\n",
       "       10,  5, 10, 20, 10, 28, 10, 11, 10, 12,  1, 20, 12, 26,  1,  1, 12,\n",
       "       10, 14, 14,  6, 15,  6, 22, 14, 26, 20,  9, 22, 20, 16, 20,  9,  1,\n",
       "       29, 20,  8,  8, 12, 10, 20,  8, 29, 12, 20,  4, 12,  7, 15, 11, 27,\n",
       "       22, 10, 12,  7, 14,  7,  7, 15, 26, 12, 11, 26, 11,  7, 12, 16, 22,\n",
       "        5, 20, 13,  6,  5, 26, 22,  6, 22,  6, 26, 26, 12,  8, 22, 11,  7,\n",
       "       26,  7,  7,  7, 12,  7,  7, 15, 20, 20, 26, 26,  6, 22, 26, 22, 15,\n",
       "       11, 14,  1, 16,  6,  7,  7, 26,  4, 16, 15, 26,  7, 11,  8,  7, 12,\n",
       "        9, 16, 15, 26, 15, 14, 27,  1,  6, 15, 27,  8,  8, 15, 12, 23,  6,\n",
       "       26,  6,  8, 16,  6, 11,  7, 22,  9,  1,  7, 22, 12, 12, 28,  9,  1,\n",
       "       16,  6,  1,  4, 14, 12, 27, 10, 13,  5,  5,  8,  8,  4, 12,  1, 26,\n",
       "        1, 10,  1, 12,  9, 12,  9, 14, 12, 12,  2, 11,  5,  6,  7,  1,  8,\n",
       "       23, 14, 15, 23, 11, 12, 16, 12, 12,  4,  8,  4, 12, 12, 27,  7, 14,\n",
       "       16, 16, 12, 23,  9, 14, 12, 22,  8,  8, 12, 10,  9, 10, 10, 29,  8,\n",
       "       10, 10, 12, 22, 12,  8,  1,  6, 12,  0,  9, 29,  3,  4, 16, 14, 16,\n",
       "        8,  7, 10,  0, 24, 22, 12, 12, 12,  8, 27,  6, 24,  5, 11, 16, 10,\n",
       "       29,  4,  8, 16, 24, 12,  8, 22, 12, 29, 12, 16, 24, 16, 14,  5,  8,\n",
       "        8,  6, 12, 15, 29, 12, 10, 12,  4,  7,  3,  7,  6, 21, 12, 24, 10,\n",
       "       10,  1,  9, 23, 10,  3, 16,  3,  3,  9,  3, 16, 26,  3, 13, 13, 15,\n",
       "       10, 11, 13, 15,  1,  9, 23, 16, 14,  2, 28,  9, 12,  1, 10,  8, 14,\n",
       "        4, 12, 10,  6, 14,  0,  1,  2,  2, 23, 14, 16, 12,  9, 12, 26,  0,\n",
       "       26, 12,  1, 12, 14, 19, 16, 12,  8, 10,  2, 12, 28, 19,  4, 12,  7,\n",
       "        9, 26, 12,  8, 10, 16, 16, 10,  1, 19,  7, 13, 12,  9, 14, 12, 19,\n",
       "        3, 27, 16, 16,  2, 27, 16, 23, 16, 23, 16, 16, 15, 16, 28, 28,  9,\n",
       "        5, 19, 14,  4,  0,  7,  6, 12,  8,  0,  4, 28, 16, 15,  6,  0, 10,\n",
       "       10, 13,  4, 17, 15, 16,  9, 16, 16,  9, 23, 23, 14,  9,  9, 15, 16,\n",
       "        2, 17,  2, 14,  7,  2,  7,  9,  9,  0, 12, 14,  2,  2,  2, 16, 26,\n",
       "       16,  2, 22, 10,  2, 13, 14,  2, 14,  2, 13,  2, 16, 12, 23,  2,  2,\n",
       "        2,  2, 27,  2, 23, 11,  2,  2,  2, 21,  2,  2,  2,  1,  2, 12, 15,\n",
       "        2,  0, 10, 23,  4, 12, 23,  2,  6,  2,  2,  2,  2,  2,  5,  3,  2,\n",
       "        2, 16,  2, 13, 13, 13, 13,  2, 21,  2, 15,  2,  2,  2,  2, 16, 26,\n",
       "        2,  2,  9,  2,  2,  2,  2,  2,  2, 21, 17,  2,  2, 21,  2,  2,  2,\n",
       "       21,  2, 26,  2, 21, 16,  2,  3, 21, 21, 21, 21, 13, 24, 16, 16,  5,\n",
       "        5,  3, 21,  2, 12, 21, 28, 21,  6, 21,  7, 17, 21, 21,  3,  2,  3,\n",
       "        6, 14, 19, 26, 13, 21, 21, 12, 21, 21, 21, 21, 14, 17, 23,  6, 21,\n",
       "       21,  2, 21, 17, 17, 17,  9,  9, 16, 17, 17, 15, 17,  0,  9, 17, 17,\n",
       "       10, 17,  6, 17, 16, 17, 17,  7, 17,  1, 17, 17, 12, 17, 14, 17, 17,\n",
       "       17, 17, 17, 17, 17, 17, 17, 14, 16, 17, 17, 13, 13, 13, 13, 13, 13,\n",
       "       13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14,\n",
       "       23,  8,  5, 16, 17, 13, 23, 14, 10, 14, 16,  5, 16,  5, 16,  9,  6,\n",
       "       12, 14, 22,  6,  2, 23,  2,  2, 12, 12,  2,  9,  6, 14, 23, 12,  4,\n",
       "        2, 13, 12,  1, 15,  2,  2,  2,  1, 12, 11, 11,  2,  9,  7,  8,  7,\n",
       "       12,  7, 13, 13,  6, 26,  6,  7,  9, 10, 10, 12, 28, 10, 23,  5,  6,\n",
       "       15, 10,  9, 16,  4, 16, 22, 16,  9,  8, 14, 14, 22, 25, 12, 24, 14,\n",
       "        6,  2, 15, 14,  5, 12, 14, 10, 16, 14, 10,  4, 14,  5, 12, 17, 16,\n",
       "        8, 16,  2, 26,  1, 13,  7, 14,  1, 24,  5, 12,  9, 12, 23, 18,  8,\n",
       "        6,  4,  4, 14, 14, 23,  9, 24, 10,  2, 12, 16,  9,  3,  7,  1, 16,\n",
       "       28,  2, 12,  6, 25,  5, 28,  1,  2,  2, 16, 24, 14, 25,  8,  4, 19,\n",
       "       12, 12, 11, 14, 12, 28, 25,  6, 16,  8, 14, 12, 18,  5, 14, 14, 14,\n",
       "        9, 12,  8, 25, 26, 25, 12,  2,  5,  2, 25,  4, 25,  2,  2,  2, 25,\n",
       "        6, 22,  0, 16, 25, 27, 25, 14, 10,  5, 12, 14,  6,  8, 14,  8, 16,\n",
       "       26, 14, 24, 12,  6, 10, 15, 22,  5, 10, 15,  8, 18, 14, 27, 19, 16,\n",
       "       18,  7, 12, 15, 18, 14,  8, 12,  2, 24,  4, 14,  6, 26,  3,  5,  5,\n",
       "        6, 13, 22,  8, 12,  3, 12, 16,  4, 22, 14, 22,  8, 14, 15, 16,  1,\n",
       "        6,  9,  8, 10, 23, 12,  1, 24, 14, 28, 23,  7, 28, 24])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: 0 (11 docs)\n",
      "china, urban, town, metropolitan, tourism, qing, modernity, beirut, landscape, verde\n",
      "\n",
      "Cluster: 1 (35 docs)\n",
      "printing, resistivity, regression, xerography, sequential, sinkholes, statistical, uml, markov, industry\n",
      "\n",
      "Cluster: 2 (85 docs)\n",
      "teachers, colleges, college, curriculum, teacher, alliance, workforce, technicians, manufacturing, industry\n",
      "\n",
      "Cluster: 3 (16 docs)\n",
      "fellowship, postdoctoral, he, informatics, redshift, galaxies, training, she, stars, astronomy\n",
      "\n",
      "Cluster: 4 (24 docs)\n",
      "straightening, repair, regression, nigms, anthracis, heat, bacillus, linear, damaged, error\n",
      "\n",
      "Cluster: 5 (28 docs)\n",
      "curvature, manifolds, metrics, einstein, riemannian, conformal, jets, kona, transverse, lows\n",
      "\n",
      "Cluster: 6 (49 docs)\n",
      "equations, dynamical, schrodinger, nonlinear, approximation, resonances, asymptotic, waves, maps, fluid\n",
      "\n",
      "Cluster: 7 (43 docs)\n",
      "operators, harmonic, ergodic, operator, theorems, integrals, equations, spaces, toeplitz, polynomial\n",
      "\n",
      "Cluster: 8 (48 docs)\n",
      "polymer, films, diamond, amorphous, deposition, polymers, md, plasma, micro, metallic\n",
      "\n",
      "Cluster: 9 (42 docs)\n",
      "conference, meeting, symposium, algebraic, indigenous, 2002, statistics, melbourne, seminar, stochastic\n",
      "\n",
      "Cluster: 10 (48 docs)\n",
      "sensor, manufacturing, autonomous, locomotion, robots, voting, swiss, packages, detachment, lam\n",
      "\n",
      "Cluster: 11 (21 docs)\n",
      "arithmetic, functions, automorphic, numbers, conjecture, symmetric, modular, galois, theory, eisenstein\n",
      "\n",
      "Cluster: 12 (101 docs)\n",
      "optimization, sdp, contract, random, semidefinite, sediment, quadratic, mappings, ultrabroadband, required\n",
      "\n",
      "Cluster: 13 (43 docs)\n",
      "available, not, zygotic, zygomycota, zygomycetes, zygmund, zworski, zurich, zuni, zro2\n",
      "\n",
      "Cluster: 14 (66 docs)\n",
      "superconductors, quantum, magnetic, helium, spin, crystals, superconducting, semiconductor, superfluid, molecules\n",
      "\n",
      "Cluster: 15 (30 docs)\n",
      "algebras, quantum, manifolds, subfactors, spaces, operator, theory, string, topology, commutative\n",
      "\n",
      "Cluster: 16 (65 docs)\n",
      "workshop, terrorist, attacks, attitudes, japan, adolescents, kdi, harvard, wtc, russian\n",
      "\n",
      "Cluster: 17 (34 docs)\n",
      "abroad, dr, fellowship, twenty, oxford, netherlands, archaeological, exotic, amb, soil\n",
      "\n",
      "Cluster: 18 (5 docs)\n",
      "mantle, subduction, arc, costa, passcal, factory, wedge, magma, receiver, cocos\n",
      "\n",
      "Cluster: 19 (8 docs)\n",
      "iron, arsenic, corrosion, haiwee, tectonically, phosphorus, sediments, srb, mobilization, gulf\n",
      "\n",
      "Cluster: 20 (20 docs)\n",
      "microbial, fellowship, biology, bacterial, fungal, fungi, bacteria, training, virulence, endophytes\n",
      "\n",
      "Cluster: 21 (26 docs)\n",
      "fellowship, mathematical, sciences, fellowships, zygotic, zygomycota, zygomycetes, zygmund, zworski, zurich\n",
      "\n",
      "Cluster: 22 (31 docs)\n",
      "algebraic, curves, geometry, moduli, varieties, algebra, polytopes, riemann, hilbert, abelian\n",
      "\n",
      "Cluster: 23 (25 docs)\n",
      "magnetic, magnetosphere, particle, ring, particles, ionosphere, acceleration, inner, energetic, cmes\n",
      "\n",
      "Cluster: 24 (14 docs)\n",
      "clay, friction, subduction, mineralogy, nankai, coefficient, shales, overconsolidated, shale, sliding\n",
      "\n",
      "Cluster: 25 (11 docs)\n",
      "crcd, curriculum, entitled, notre, dame, smart, communications, photovoltaic, pittsburgh, texas\n",
      "\n",
      "Cluster: 26 (33 docs)\n",
      "algebras, algebra, representation, symmetries, lie, commutative, algebraic, theory, geometric, matrices\n",
      "\n",
      "Cluster: 27 (13 docs)\n",
      "oceanographic, vessel, ship, ships, shipboard, operated, equipment, transceivers, unols, retrieval\n",
      "\n",
      "Cluster: 28 (17 docs)\n",
      "cad, parameterization, platform, xenon, resultants, platforms, tasks, grid, chips, desktop\n",
      "\n",
      "Cluster: 29 (8 docs)\n",
      "centrifuge, laminar, nied, shaking, liquefaction, seismic, box, earthquake, 1g, rpi\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_clusters(matrix_sample, km.labels_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "\n",
    "Z = linkage(matrix_sample.todense(), metric='cosine', method='complete')\n",
    "_ = dendrogram(Z, no_labels=True) # Plot dentrogram chart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Z_ = linkage(matrix_sample.todense()[:25], metric='cosine', method='complete')\n",
    "_ = dendrogram(Z_, no_labels=True) # Plot dentrogram chart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: 1 (7 docs)\n",
      "ethnic, tourism, chinese, workers, tourist, firms, guides, tour, welfare, beirut\n",
      "\n",
      "Cluster: 2 (5 docs)\n",
      "costa, subduction, arc, mantle, passcal, flux, rica, factory, wedge, receiver\n",
      "\n",
      "Cluster: 3 (4 docs)\n",
      "tectonically, continental, gulf, detachment, earlist, dredge, segmented, rifts, basement, accompanies\n",
      "\n",
      "Cluster: 4 (13 docs)\n",
      "magnetic, magnetosphere, ionosphere, inner, ring, particle, formalism, auroral, relativistic, ions\n",
      "\n",
      "Cluster: 5 (7 docs)\n",
      "aerosol, muon, indoex, rsvp, climate, ice, chile, rainy, ring, logger\n",
      "\n",
      "Cluster: 6 (8 docs)\n",
      "iron, arsenic, sediment, corrosion, haiwee, phosphorus, strickland, floodplain, sediments, srb\n",
      "\n",
      "Cluster: 7 (56 docs)\n",
      "customer, china, cad, nonlinear, control, platform, land, platforms, reverse, planning\n",
      "\n",
      "Cluster: 8 (29 docs)\n",
      "sdp, wavelet, polynomials, semidefinite, speckle, quadratic, integer, convex, dynamical, wavelets\n",
      "\n",
      "Cluster: 9 (62 docs)\n",
      "quantum, superconductors, magnetic, spin, superconductivity, composite, superconducting, frp, superfluid, semiconductor\n",
      "\n",
      "Cluster: 10 (22 docs)\n",
      "archaeological, brain, figurines, tumors, cyclogenesis, coils, ligand, mri, kona, agent\n",
      "\n",
      "Cluster: 11 (13 docs)\n",
      "terrorist, attacks, attitudes, wtc, public, trust, polling, actions, workshop, aftermath\n",
      "\n",
      "Cluster: 12 (10 docs)\n",
      "voting, accessibility, canopy, kent, elderly, wang, cosmos, paul, forest, harvard\n",
      "\n",
      "Cluster: 13 (75 docs)\n",
      "equations, random, conformal, regression, dynamical, monge, einstein, elliptic, manifolds, nonlinear\n",
      "\n",
      "Cluster: 14 (35 docs)\n",
      "algebraic, algebra, geometry, commutative, curves, geometric, varieties, polynomial, ideals, galois\n",
      "\n",
      "Cluster: 15 (5 docs)\n",
      "jets, manipulation, transverse, jet, robots, mixing, she, virtual, modular, associate\n",
      "\n",
      "Cluster: 16 (27 docs)\n",
      "sparse, parallel, hierarchical, matrices, software, graded, operations, constitutive, algebra, scheduling\n",
      "\n",
      "Cluster: 17 (1 docs)\n",
      "retardation, multipole, relativity, ionization, correlations, scattering, atomic, investigations, electron, higher\n",
      "\n",
      "Cluster: 18 (7 docs)\n",
      "cmes, coronal, solar, coronagraph, cme, shock, au, ulysses, sep, flares\n",
      "\n",
      "Cluster: 19 (2 docs)\n",
      "western, coral, algebraists, decadal, operator, ramsay, abreast, solomon, multi, reinforces\n",
      "\n",
      "Cluster: 20 (12 docs)\n",
      "subduction, laminar, mineralogy, table, clay, centrifuge, nied, shaking, forensic, isotope\n",
      "\n",
      "Cluster: 21 (13 docs)\n",
      "fluid, particles, immiscible, combustion, fluids, particle, opto, motion, singularities, convection\n",
      "\n",
      "Cluster: 22 (8 docs)\n",
      "mesoscale, granular, lake, classic, effect, ccsm, waves, synoptic, diffusivity, convective\n",
      "\n",
      "Cluster: 23 (11 docs)\n",
      "bone, muscle, cardiac, stimulation, breast, nerve, stretch, tendon, invasive, deformation\n",
      "\n",
      "Cluster: 24 (4 docs)\n",
      "bubble, plume, reservoir, soap, morgan, bubbles, mixing, microfluidic, monitored, injury\n",
      "\n",
      "Cluster: 25 (18 docs)\n",
      "films, amorphous, fuel, micro, deposition, friction, metrology, nano, lubrication, unusual\n",
      "\n",
      "Cluster: 26 (8 docs)\n",
      "organizational, adolescents, texts, friendship, town, movements, mental, harvard, government, agendas\n",
      "\n",
      "Cluster: 27 (13 docs)\n",
      "japan, database, workshop, ices, atlantic, nanotechnology, biological, biology, globec, integrative\n",
      "\n",
      "Cluster: 28 (36 docs)\n",
      "molecules, photodissociation, clusters, films, charge, droplets, crystals, polymers, helium, magnetic\n",
      "\n",
      "Cluster: 29 (12 docs)\n",
      "he, redshift, galaxies, asymmetric, stars, astronomy, stereogenic, membered, slit, his\n",
      "\n",
      "Cluster: 30 (18 docs)\n",
      "printing, xerography, manufacturing, swiss, lam, polymer, plastics, sequential, fleming, color\n",
      "\n",
      "Cluster: 31 (14 docs)\n",
      "crcd, curriculum, entitled, notre, dame, communications, chile, universidad, photovoltaic, pittsburgh\n",
      "\n",
      "Cluster: 32 (17 docs)\n",
      "oceanographic, vessel, ship, ships, shipboard, operated, equipment, transceivers, unols, retrieval\n",
      "\n",
      "Cluster: 33 (21 docs)\n",
      "conference, symposium, meeting, statistics, melbourne, stochastic, 2002, mg2, manipulators, 28th\n",
      "\n",
      "Cluster: 34 (13 docs)\n",
      "workshop, kdi, workshops, meetings, pbo, vancouver, congress, gaim, chlamydomonas, igbp\n",
      "\n",
      "Cluster: 35 (92 docs)\n",
      "algebras, theory, spaces, manifolds, representation, arithmetic, operator, lie, symmetries, conjecture\n",
      "\n",
      "Cluster: 36 (17 docs)\n",
      "czech, 3d, resistivity, dye, sinkholes, turbulent, cave, magma, 2d, turbulence\n",
      "\n",
      "Cluster: 37 (12 docs)\n",
      "optical, ultrabroadband, gravitational, fiber, fs, semiconductor, stars, cavity, frog, ligo\n",
      "\n",
      "Cluster: 38 (1 docs)\n",
      "anthracis, bacillus, outbreak, virulence, quest, anthrax, sequence, strains, phylogenetic, comparisons\n",
      "\n",
      "Cluster: 39 (25 docs)\n",
      "straightening, earthquake, repair, seismic, heat, wind, shales, damage, damaged, overconsolidated\n",
      "\n",
      "Cluster: 40 (12 docs)\n",
      "sensor, liquid, xenon, prosthesis, stimulator, module, smart, interfacial, retinal, capillary\n",
      "\n",
      "Cluster: 41 (76 docs)\n",
      "teachers, colleges, college, curriculum, teacher, alliance, technicians, manufacturing, industry, umeb\n",
      "\n",
      "Cluster: 42 (15 docs)\n",
      "collider, detector, assistive, disabilities, neutrinos, neutrino, persons, babar, experiment, projects\n",
      "\n",
      "Cluster: 43 (86 docs)\n",
      "fellowship, mathematical, sciences, postdoctoral, abroad, microbial, bacterial, fungal, biology, dr\n",
      "\n",
      "Cluster: 44 (46 docs)\n",
      "available, not, packages, cheating, macroeconomics, cheat, encouragement, retired, economists, papers\n",
      "\n",
      "Cluster: 45 (10 docs)\n",
      "fellowships, mathematical, nigms, sciences, rna, magazine, antisense, genes, translations, ribozymes\n",
      "\n",
      "Cluster: 46 (1 docs)\n",
      "required, no, abstract, zygotic, zygomycota, zygomycetes, zygmund, zworski, zurich, zuni\n",
      "\n",
      "Cluster: 47 (1 docs)\n",
      "contract, zygotic, zygomycota, zygomycetes, zygmund, zworski, zurich, zuni, zro2, zr\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clusters = fcluster(Z, 0.99, criterion='distance') # Create flat clusters by distance threshold\n",
    "\n",
    "print_clusters(matrix_sample, clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Topic modeling demo\n",
    "#!pip3 install gensim\n",
    "\n",
    "# Fast and simple tokenization\n",
    "new_vectorizer = TfidfVectorizer()\n",
    "word_tokenizer = new_vectorizer.build_tokenizer()\n",
    "tokenized_text = [word_tokenizer(doc) for doc in abstracts]\n",
    "\n",
    "# Train LDA model\n",
    "from gensim import corpora, models\n",
    "dictionary = corpora.Dictionary(tokenized_text)\n",
    "lda_corpus = [dictionary.doc2bow(text) for text in tokenized_text]\n",
    "lda_model = models.LdaModel(lda_corpus, id2word=dictionary, num_topics=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar terms to: activate\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1.0, 'activate'),\n",
       " (0.4467520998979391, 'coactivators'),\n",
       " (0.42889032702581664, 'progesterone'),\n",
       " (0.32482802354394924, 'src'),\n",
       " (0.2686122567729347, 'glucan'),\n",
       " (0.2497143994273816, 'ovarian'),\n",
       " (0.23081499344794168, 'actin'),\n",
       " (0.22417103095601956, 'p53'),\n",
       " (0.20983754293502693, 'immuno'),\n",
       " (0.20794789527290336, 'steroid')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "term_index = 1000\n",
    "print(\"Similar terms to:\", features[term_index])\n",
    "# Get most similar terms according to the cosine similarity of their vectors (columns in the term-document matrix)\n",
    "heapq.nlargest(10, zip(cosine_similarity(tfidf_matrix[:,term_index].todense().T, tfidf_matrix.todense().T)[0], features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-24 10:41:47,280 : INFO : collecting all words and their counts\n",
      "2021-02-24 10:41:47,281 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2021-02-24 10:41:47,780 : INFO : collected 63620 word types from a corpus of 2817564 raw words and 9923 sentences\n",
      "2021-02-24 10:41:47,781 : INFO : Loading a fresh vocabulary\n",
      "2021-02-24 10:41:47,957 : INFO : effective_min_count=3 retains 29581 unique words (46% of original 63620, drops 34039)\n",
      "2021-02-24 10:41:47,958 : INFO : effective_min_count=3 leaves 2774058 word corpus (98% of original 2817564, drops 43506)\n",
      "2021-02-24 10:41:48,052 : INFO : deleting the raw counts dictionary of 63620 items\n",
      "2021-02-24 10:41:48,054 : INFO : sample=0.001 downsamples 26 most-common words\n",
      "2021-02-24 10:41:48,054 : INFO : downsampling leaves estimated 2161148 word corpus (77.9% of prior 2774058)\n",
      "2021-02-24 10:41:48,125 : INFO : estimated required memory for 29581 words and 100 dimensions: 38455300 bytes\n",
      "2021-02-24 10:41:48,126 : INFO : resetting layer weights\n",
      "2021-02-24 10:41:54,248 : INFO : training model with 4 workers on 29581 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2021-02-24 10:41:55,260 : INFO : EPOCH 1 - PROGRESS: at 80.54% examples, 1725188 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-24 10:41:55,496 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-24 10:41:55,497 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-24 10:41:55,501 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-24 10:41:55,502 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-24 10:41:55,503 : INFO : EPOCH - 1 : training on 2817564 raw words (2161615 effective words) took 1.3s, 1726802 effective words/s\n",
      "2021-02-24 10:41:56,508 : INFO : EPOCH 2 - PROGRESS: at 78.81% examples, 1700174 words/s, in_qsize 8, out_qsize 0\n",
      "2021-02-24 10:41:56,767 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-24 10:41:56,773 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-24 10:41:56,777 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-24 10:41:56,779 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-24 10:41:56,779 : INFO : EPOCH - 2 : training on 2817564 raw words (2161275 effective words) took 1.3s, 1698268 effective words/s\n",
      "2021-02-24 10:41:57,785 : INFO : EPOCH 3 - PROGRESS: at 79.75% examples, 1719869 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-24 10:41:58,022 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-24 10:41:58,027 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-24 10:41:58,030 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-24 10:41:58,033 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-24 10:41:58,034 : INFO : EPOCH - 3 : training on 2817564 raw words (2161055 effective words) took 1.3s, 1726896 effective words/s\n",
      "2021-02-24 10:41:59,039 : INFO : EPOCH 4 - PROGRESS: at 79.12% examples, 1707488 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-24 10:41:59,288 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-24 10:41:59,291 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-24 10:41:59,295 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-24 10:41:59,299 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-24 10:41:59,300 : INFO : EPOCH - 4 : training on 2817564 raw words (2161149 effective words) took 1.3s, 1712154 effective words/s\n",
      "2021-02-24 10:42:00,304 : INFO : EPOCH 5 - PROGRESS: at 79.75% examples, 1721620 words/s, in_qsize 7, out_qsize 0\n",
      "2021-02-24 10:42:00,555 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2021-02-24 10:42:00,560 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2021-02-24 10:42:00,561 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2021-02-24 10:42:00,562 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2021-02-24 10:42:00,563 : INFO : EPOCH - 5 : training on 2817564 raw words (2161581 effective words) took 1.3s, 1714997 effective words/s\n",
      "2021-02-24 10:42:00,564 : INFO : training on a 14087820 raw words (10806675 effective words) took 6.3s, 1711191 effective words/s\n"
     ]
    }
   ],
   "source": [
    "import gensim # Make sure you also have cython installed to accelerate computation!\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# Train word2vec model\n",
    "vectors = gensim.models.Word2Vec(tokenized_text, size=100, window=5, min_count=3, workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.90953004,  0.81836754, -1.2900009 ,  1.1606756 ,  1.4592584 ,\n",
       "        0.54667056,  1.7854558 ,  0.92765826,  1.3956335 , -0.177849  ,\n",
       "        0.09046485, -1.6987875 ,  1.357826  , -0.11927579, -0.014988  ,\n",
       "        0.23494846, -0.19581324,  0.7204914 ,  0.64068794, -3.3971977 ,\n",
       "        0.3191342 ,  1.3723253 , -0.9613194 , -0.54091525, -0.9888401 ,\n",
       "        1.1723601 , -0.07445102, -0.799723  ,  0.07201891, -0.05726195,\n",
       "        0.45764053, -0.19950882,  0.43562016, -1.721234  , -0.23484747,\n",
       "       -0.876995  , -0.5557397 ,  0.04679805, -1.5417254 ,  0.16043055,\n",
       "       -1.5130715 ,  0.7550467 , -0.49763212,  0.7748843 ,  0.01341338,\n",
       "        1.4457353 , -1.7432455 ,  1.0071301 ,  1.8084767 , -0.37255585,\n",
       "       -1.2984295 , -0.05650708,  1.1424354 , -0.6647455 ,  1.8810067 ,\n",
       "       -0.8860951 ,  0.37330547,  0.2339391 ,  0.16134171, -0.04955637,\n",
       "       -0.1414454 , -1.6622316 ,  0.43541706, -2.6808136 , -0.05063106,\n",
       "        0.00950527,  0.81399316,  1.1374755 ,  0.49267164, -1.7269216 ,\n",
       "       -0.01652187,  0.86887765, -0.02409381, -1.0919927 , -0.7023016 ,\n",
       "        0.19004855,  0.7278587 , -1.0377477 ,  0.31784612,  0.7207524 ,\n",
       "        0.7725844 , -0.8420504 , -0.07380578, -0.31754485,  0.35220513,\n",
       "       -1.271246  ,  1.3212774 , -0.82198375, -0.27976125,  0.42537472,\n",
       "       -1.3535289 , -1.3029581 , -0.3789153 ,  1.8055253 , -0.51299965,\n",
       "       -0.60946465, -1.130077  ,  0.4507952 ,  0.5643211 , -0.69070345],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect a word vector\n",
    "vectors.wv['process']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-24 10:42:00,591 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: process\n",
      "[('strategy', 0.7257898449897766), ('mechanism', 0.6809995770454407), ('product', 0.6792237758636475), ('architecture', 0.6622252464294434), ('manner', 0.6400573253631592), ('way', 0.6343898773193359), ('paradigm', 0.6276974678039551), ('activity', 0.6218494176864624), ('formulation', 0.6190251708030701), ('system', 0.6143497228622437)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect words with vectors most similar to a given word\n",
    "print(\"Most similar to:\", 'process')\n",
    "print(vectors.wv.most_similar('process'))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar to: ['process', 'strategy']\n",
      "[('paradigm', 0.7559958100318909), ('approach', 0.740641176700592), ('methodology', 0.7338005304336548), ('architecture', 0.7316803336143494), ('product', 0.7177249193191528), ('protocol', 0.698704719543457), ('way', 0.6967167854309082), ('formulation', 0.69472336769104), ('mechanism', 0.6942002773284912), ('tool', 0.6924450397491455)]\n"
     ]
    }
   ],
   "source": [
    "# ...or combination or words (average vector)\n",
    "print(\"Most similar to:\", ['process', 'strategy'])\n",
    "print(vectors.wv.most_similar(['process', 'strategy']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5949236\n",
      "0.3743288\n",
      "0.3559913\n",
      "0.5727541\n"
     ]
    }
   ],
   "source": [
    "# Inspect cosine similarities between specific words\n",
    "print(vectors.wv.similarity('technology', 'infrastructure'))\n",
    "print(vectors.wv.similarity('technology', 'system'))\n",
    "print(vectors.wv.similarity('technology', 'consumer'))\n",
    "print(vectors.wv.similarity('technology', 'advanced'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['exacerbate', 'interface', 'fire', 'pathways', 'fewer']\n"
     ]
    }
   ],
   "source": [
    "words = [list(vectors.wv.vocab.keys())[(i+1)*1200] for i in range(5)]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Jewish', 0.8873485326766968), ('sects', 0.8749203681945801), ('stop', 0.8700597286224365), ('tan', 0.8687407970428467), ('maliciously', 0.8622428178787231), ('Has', 0.860679030418396), ('domestically', 0.8603434562683105), ('owners', 0.8577088117599487), ('favors', 0.8572164177894592), ('overly', 0.8551536798477173)]\n",
      "[('interfaces', 0.8546984791755676), ('nanoscale', 0.6302165985107422), ('layer', 0.6252212524414062), ('coupling', 0.618942141532898), ('circuit', 0.6170817613601685), ('architecture', 0.6104079484939575), ('interaction', 0.6074636578559875), ('continuum', 0.6067649126052856), ('switch', 0.5920110940933228), ('link', 0.5891084671020508)]\n",
      "[('vegetation', 0.8950409293174744), ('seasonal', 0.8772874474525452), ('forest', 0.8685150146484375), ('climatic', 0.8591132164001465), ('climates', 0.838323712348938), ('dispersal', 0.8271552920341492), ('floodplain', 0.8205798864364624), ('flood', 0.8170578479766846), ('interannual', 0.8142204284667969), ('arctic', 0.8088667392730713)]\n",
      "[('mechanisms', 0.8553897738456726), ('traits', 0.8215985298156738), ('regulation', 0.815657377243042), ('reactions', 0.7976272106170654), ('enzymes', 0.7889086604118347), ('proteins', 0.7825480103492737), ('metabolism', 0.7800180912017822), ('intermediates', 0.7742017507553101), ('signaling', 0.7706302404403687), ('pathway', 0.7690191864967346)]\n",
      "[('weaker', 0.8362911343574524), ('differently', 0.8350362777709961), ('considerably', 0.8046174049377441), ('Rather', 0.8022627234458923), ('older', 0.792182445526123), ('less', 0.7910919189453125), ('frequently', 0.7799718976020813), ('stronger', 0.7787488698959351), ('acclimate', 0.7777070999145508), ('dangerous', 0.7743433713912964)]\n"
     ]
    }
   ],
   "source": [
    "print(vectors.wv.most_similar(words[0]))\n",
    "print(vectors.wv.most_similar(words[1]))\n",
    "print(vectors.wv.most_similar(words[2]))\n",
    "print(vectors.wv.most_similar(words[3]))\n",
    "print(vectors.wv.most_similar(words[4]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
